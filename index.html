<!DOCTYPE html>
<html lang="en-us">
	<head>
		<meta charset="UTF-8">
		<title>INFOTABS</title>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="theme-color" content="#157879">
		<link rel="stylesheet" href="css/normalize.css">
		<link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
		<link rel="stylesheet" href="css/cayman.css">
	</head>
	<body>
		<section class="page-header">
			<h1><img src="figures/logo_final.jpg" style="max-width:40%;"></h1>
			<a href="" class="btn">Paper</a>
			<a href="" class="btn">Dataset</a>
			<a href="" class="btn">Explore</a>
			<a href="" class="btn">Code</a> 
			<a href="" class="btn">Video</a>
			<a href="" class="btn">PPT</a><br>
			<a href="" class="btn">Knowledge + InfoTabS</a>
			<a href="" class="btn">TabPert</a>
		</section>
		<section class="main-content">
    <h1>Leveraging LLMs for Synchronizing Information Across Multilingual Tables</h1>
    <h2>About</h2>
    <p style="text-align: justify;">
        The vast amount of online information today poses challenges for non-English speakers, as much of it is concentrated in high-resource languages like English, Spanish, and French. Wikipedia reflects this imbalance, with content in low-resource languages often outdated or incomplete. This paper explores large language models (LLMs) for multilingual information synchronization, using zero-shot prompting as a scalable solution. We introduce the Information Updation dataset, simulating the process of updating outdated Wikipedia tables, and evaluate LLM performance.
    </p>
    <p style="text-align: justify;">TL;DR: We propose a novel dataset and LLM-based approach for multilingual table synchronization, significantly improving information updation accuracy.</p>
    
    <h2>Procedure</h2>
    <p style="text-align: justify;">
        We construct an Information Updation dataset by extracting outdated and updated Wikipedia tables across multiple languages. Using a task decomposition approach, we employ large language models to enhance synchronization accuracy. Our evaluation includes comparisons with rule-based methods and an in-depth analysis of model performance on various linguistic structures.
    </p>
    
    <h2>Example</h2>
    <p style="text-align: justify; display:inline;">Below is an example of information synchronization from our dataset. On the right is a reference table in a high-resource language, and on the left is an outdated table in a low-resource language. Updates made by our model are highlighted.</p>
    <p style="margin-left:10%; margin-right:10%;"><img src="figures/example.png" style="max-width:95%;"></p>
    
    <h2>Methodology</h2>
    <p style="text-align: justify;">
        We propose a hierarchical task decomposition strategy for LLM-based synchronization. This includes:
        <ul>
            <li>Translation: Converting tables into a common language (English) for uniform processing.</li>
            <li>Knowledge Graph Construction: Representing tables as structured graphs for improved reasoning.</li>
            <li>Alignment and Merging: Identifying and integrating missing or outdated information.</li>
            <li>Final Update: Refining the synchronized table and translating it back into the target language.</li>
        </ul>
    </p>
<!--     <figure>
        <img src="figures/methodology.png" style="max-width:100%;">
        <figcaption>Overview of our LLM-driven table synchronization framework.</figcaption>
    </figure> -->
    
    <h2>Dataset Statistics</h2>
    <p style="text-align: justify;">
        Our dataset spans multiple Wikipedia categories and languages. Below is a summary of dataset statistics:
    </p>
    <div>
        <table style="margin-left:15%; margin-right:15%;">
            <thead>
                <tr>
                    <th>Data Split</th>
                    <th>Number of Tables</th>
                    <th>Number of Pairs</th>
                </tr>
            </thead>
            <tbody align="center">
                <tr><td>Train</td><td>1800</td><td>17000</td></tr>
                <tr><td>Dev</td><td>250</td><td>2250</td></tr>
                <tr><td>Test</td><td>250</td><td>2250</td></tr>
            </tbody>
        </table>
    </div>
    <br><br>
    <div style="text-align:center;">
        <table>
            <thead>
                <tr>
                    <th>Data Split</th>
                    <th>Cohen's Kappa</th>
                    <th>Human Performance</th>
                    <th>Majority Agreement</th>
                </tr>
            </thead>
            <tbody align="center">
                <tr><td>Dev</td><td>0.81</td><td>80.5%</td><td>94.2%</td></tr>
                <tr><td>Test</td><td>0.79</td><td>82.1%</td><td>95.0%</td></tr>
            </tbody>
        </table>
    </div>


		
			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>People</h2>
			<p style="text-align: justify;"> The INFOSYNC dataset is prepared at the <a href="https://www.cs.utah.edu/"> School of Computing</a> of <a href="https://www.cs.utah.edu/">University of Utah</a> and IIT Guwahati by the following people: </p>
			<figure>
				<img src="figures/vivekg.jpg" style="width:25%; height:300px;">
				<img src="figures/Siddharth.jpg" style="width:25%; height:300px;">
				<img src="" style="width:21%;height:300px;">
				<img src="figures/Ankita.jpg" style="width:23%;height:300px;">
				<figcaption>From left to right, <a href="https://vgupta123.github.io">Vivek Gupta</a>,Siddharth Khincha,Tushar Kataria and Ankita Anand. </figcaption>
			</figure>
			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Citation</h2>
			<p style="text-align: justify;"> Please cite our paper as below if you use the INFOTABS dataset.</p>
			<pre><code>

<!-- 				citation -->
			</code></pre>
			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Acknowledgement</h2>
			<p style="text-align: justify;">Authors thank members of the <a href="https://svivek.com/">Utah NLP group </a> and IIT Guwahati for their valuable insights and
			suggestions at various stages of the project; and <a href="https://2025.naacl.org/">NAACL 2025</a> reviewers for pointers to
			related works, corrections, and helpful comments. Authors thank the largest free resource <a href="https://en.wikipedia.org/wiki/Main_Page"> Wikipedia</a> for InfoTabS tables.</p>
			<footer class="site-footer">
				<span class="site-footer-owner"><a href="https://infosync.github.io">INFOSYNC</a> is maintained by <a href="https://vgupta123.github.io">Vivek Gupta</a>.</span>
				<span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman</a> theme by <a href="https://github.com/jasonlong">jasonlong</a>.</span>
			</footer>
		</section>
	</body>
</html>
