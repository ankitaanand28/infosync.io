<!DOCTYPE html>
<html lang="en-us">
	<head>
		<meta charset="UTF-8">
		<title>INFOTABS</title>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="theme-color" content="#157879">
		<link rel="stylesheet" href="css/normalize.css">
		<link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
		<link rel="stylesheet" href="css/cayman.css">
	</head>
	<body>
		<section class="page-header">
			<h1><img src="figures/logo.png" style="max-width:40%;"></h1>
			<a href="" class="btn">Paper</a>
			<a href="" class="btn">Dataset</a>
<!-- 			<a href="" class="btn">Explore</a> -->
			<a href="" class="btn">Code</a> 
			<a href="" class="btn">Video</a>
			<a href="" class="btn">PPT</a><br>
			<a href="" class="btn">Knowledge + InfoTabS</a>
			<a href="" class="btn">TabPert</a>
		</section>
		<section class="main-content">
    <h1>Leveraging LLMs for Synchronizing Information Across Multilingual Tables</h1>
    <h2>About</h2>
    <p style="text-align: justify;">
        The vast amount of online information today poses challenges for non-English speakers, as much of it is concentrated in high-resource languages like English, Spanish, and French. Wikipedia reflects this imbalance, with content in low-resource languages often outdated or incomplete. This paper explores large language models (LLMs) for multilingual information synchronization, using zero-shot prompting as a scalable solution. We introduce the Information Updation dataset, simulating the process of updating outdated Wikipedia tables, and evaluate LLM performance.
    </p>
    <p style="text-align: justify;">TL;DR: We propose a novel dataset and LLM-based approach for multilingual table synchronization, significantly improving information updation accuracy.</p>
    
    <h2>Procedure</h2>
    <p style="text-align: justify;">
        We construct an Information Updation dataset by extracting outdated and updated Wikipedia tables across multiple languages. Using a task decomposition approach, we employ large language models to enhance synchronization accuracy. Our evaluation includes comparisons with rule-based methods and an in-depth analysis of model performance on various linguistic structures.
    </p>
    
    <h2>Example</h2>
    <p style="text-align: justify; display:inline;">Below is an example of information synchronization from our dataset. On the right is a reference table in a high-resource language, and on the left is an outdated table in a low-resource language. Updates made by our model are highlighted.</p>
    <p style="margin-left:10%; margin-right:10%;"><img src="figures/example.png" style="max-width:95%;"></p>
    
    <h2>Methodology</h2>
    <p style="text-align: justify;">
        We propose a hierarchical task decomposition strategy for LLM-based synchronization. This includes:
        <ul>
            <li>Translation: Converting tables into a common language (English) for uniform processing.</li>
            <li>Knowledge Graph Construction: Representing tables as structured graphs for improved reasoning.</li>
            <li>Alignment and Merging: Identifying and integrating missing or outdated information.</li>
            <li>Final Update: Refining the synchronized table and translating it back into the target language.</li>
        </ul>
    </p>
<!--     <figure>
        <img src="figures/methodology.png" style="max-width:100%;">
        <figcaption>Overview of our LLM-driven table synchronization framework.</figcaption>
    </figure> -->
    
    <h2>Dataset Statistics</h2>
    <p style="text-align: justify;">
        Our dataset spans multiple Wikipedia categories and languages. Below is a summary of dataset statistics:
    </p>
    <div>
        <table style="margin-left:15%; margin-right:15%;">
            <thead>
                <tr>
                    <th>Data Split</th>
                    <th>Number of Tables</th>
                    <th>Number of Pairs</th>
                </tr>
            </thead>
            <tbody align="center">
                <tr><td>Train</td><td>1800</td><td>17000</td></tr>
                <tr><td>Dev</td><td>250</td><td>2250</td></tr>
                <tr><td>Test</td><td>250</td><td>2250</td></tr>
            </tbody>
        </table>
    </div>
    <br><br>
    <div style="text-align:center;">
        <table>
            <thead>
                <tr>
                    <th>Data Split</th>
                    <th>Cohen's Kappa</th>
                    <th>Human Performance</th>
                    <th>Majority Agreement</th>
                </tr>
            </thead>
            <tbody align="center">
                <tr><td>Dev</td><td>0.81</td><td>80.5%</td><td>94.2%</td></tr>
                <tr><td>Test</td><td>0.79</td><td>82.1%</td><td>95.0%</td></tr>
            </tbody>
        </table>
    </div>


			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Knowledge + InfoTabS</h2>
			<p style="text-align: justify;"> You should check our <a href="https://2021.naacl.org/">NAACL 2021</a> paper which <a href="https://knowledge-infotabs.github.io">enhance InfoTabS</a> with extra Knowledge.</p>
			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>TabPert</h2>
			<p style="text-align: justify;"> You should check our <a href="https://2021.emnlp.org">EMNLP 2021</a> paper which is a <a href="https://tabpert.github.io">tabular perturbation platform</a> to generate counterfactual examples.</p>

			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>People</h2>
			<p style="text-align: justify;"> The INFOTABS dataset is prepared at the <a href="https://www.cs.utah.edu/"> School of Computing</a> of <a href="https://www.cs.utah.edu/">University of Utah</a> by the following people: </p>
			<figure>
				<img src="figures/vivekg.jpg" style="width:25%;">
				<img src="figures/maitrey.jpeg" style="width:25%;">
				<img src="figures/pegah.png" style="width:21%;">
				<img src="figures/viveks.jpg" style="width:23%;">
				<figcaption>From left to right, <a href="https://vgupta123.github.io">Vivek Gupta</a>, <a href="https://sites.google.com/view/maitreymehta/home">Maitrey Mehta</a>, <a href="https://sites.google.com/view/pnokhiz/home">Pegah Nokhiz</a> and <a href="https://svivek.com/">Vivek Srikumar</a>. </figcaption>
			</figure>
			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Citation</h2>
			<p style="text-align: justify;"> Please cite our paper as below if you use the INFOTABS dataset.</p>
			<pre><code>@inproceedings{gupta-etal-2020-infotabs,
    title = "{INFOTABS}: Inference on Tables as Semi-structured Data",
    author = "Gupta, Vivek  and
      Mehta, Maitrey  and
      Nokhiz, Pegah  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.210",
    pages = "2309--2324",
    abstract = "In this paper, we observe that semi-structured tabulated text is ubiquitous; understanding them requires not only comprehending the meaning of text fragments, but also implicit relationships between them. We argue that such data can prove as a testing ground for understanding how we reason about information. To study this, we introduce a new dataset called INFOTABS, comprising of human-written textual hypotheses based on premises that are tables extracted from Wikipedia info-boxes. Our analysis shows that the semi-structured, multi-domain and heterogeneous nature of the premises admits complex, multi-faceted reasoning. Experiments reveal that, while human annotators agree on the relationships between a table-hypothesis pair, several standard modeling strategies are unsuccessful at the task, suggesting that reasoning about tables can pose a difficult modeling challenge.",
}</code></pre>
			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Acknowledgement</h2>
			<p style="text-align: justify;">Authors thank members of the <a href="https://svivek.com/">Utah NLP group</a> for their valuable insights and
			suggestions at various stages of the project; and <a href="https://acl2020.org/">ACL 2020</a> reviewers for pointers to
			related works, corrections, and helpful comments. Authors thank the largest free resource <a href="https://en.wikipedia.org/wiki/Main_Page"> Wikipedia</a> for InfoTabS tables. We are also indebted to the
			many anonymous <a href="https://www.mturk.com/"> Turkers</a> who helped craft the dataset.  We acknowledge the support
			of the support of NSF Grants No. 1822877 and 1801446, and a generous gift from
			<a href="https://research.google/" >Google</a>.</p>
			<footer class="site-footer">
				<span class="site-footer-owner"><a href="https://infotabs.github.io">INFOTABS</a> is maintained by <a href="https://vgupta123.github.io">Vivek Gupta</a>.</span>
				<span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman</a> theme by <a href="https://github.com/jasonlong">jasonlong</a>.</span>
			</footer>
		</section>
	</body>
</html>
